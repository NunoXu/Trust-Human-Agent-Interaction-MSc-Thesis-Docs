% This is "UserStudies.tex"
% A content sub-file for Trustfull Action Suggestion Thesis Extended Abstract

\section{User Studies}
\label{sec:UserStudies}

In order to evaluate the model we performed a user study in a Investor Game type scenario, with the intent to create an environment where the human participant would need to make a quantitative choice representing his trust in the agent. These studies were performed in collaboration with Henriques for his thesis work on \textit{Rapport - Establishing Harmonious Relationship Between Robots and Humans} \cite{todo}, as by having similar evaluation goals we decided that a joint effort would improve the overall quality of our work.

\subsection{Quick Numbers Scenario}
\label{subsec:QuickNumbersScenario}

As we approached the problem of evaluating the models proposed in this dissertation, we found that there was a lack of dedicated Trust or Rapport evaluation scenarios. On one hand, there was a lack of attempts to encompass more than one dimension of trust, and on the other, there was a lack of studies that approach Rapport on robotic agents while at the same time, attempt to build rapport using the three components of rapport: positivity, coordination and mutual attention. While the recent study by Salem, et. al.\cite{Salem2015b} addresses the role of robot task performance in trust, no study was found addressing perceived agent willingness to perform the task and its effect on trust. Therefore, we created a novel scenario \emph{Quick Numbers}, based on the Trust Game \cite{JoyceBergJohnDickhaut}, that would enable us to evaluate how both task performance and willingness would jointly affect trust and observe all three components of rapport. The scenario was developed with the intention of evaluating a Trust model and a Rapport model, either separately or together.

In \emph{Quick Numbers}, a human subject is tasked with gaining as many resources as possible. He starts with a fixed amount and is given the opportunity of playing a game that can multiply his resources. The game starts by asking for a resource investment, and at the end, a multiplied amount of this investment is given back according to the player's performance. The virtual agent will also participate in this first step as though it is also a subject, also playing the game simultaneously with the human and sharing the same goal of getting the maximum amount of resources. At this point, the human should be able to perceive the agent's ability in the game. After finishing the game, the human will be asked to fill out a questionnaire, and the virtual agent will give the human the opportunity to invest in the next game, increasing the maximum potential return. In this phase, the virtual agent will have the opportunity to try and convince the human to invest or increase the investment by trying to manipulate trust. When the human returns the agent gives back as much as it wishes to give. This conjunction of different phases enables trust to be addressed in three distinct contexts: the ability to perform the task, willingness to perform the task, and willingness to return the investment.

%Requires review after document structure
In order to evaluate rapport and trust, participants will answer 3 questionnaires, one before playing with the virtual agent, one after investing on the agent but before knowing the result, and another after the investment return is given back. In the following paragraphs, we will detail the scenario, the procedures and methodologies of the study applied to our thesis, followed by the sample description.

\subsubsection{Agent's \ac{AI}}
An \ac{AI} was created to progress through the scenario, with it being mostly scripted reactionary events where the Agent would just press a button when perceiving some specific change in the scenario. But one part we should discuss is the \ac{AI} for the scenario's game, where although simple, some effort was given to make it parametrizable, in order to adjust the agent's ability in the game. The \ac{AI} was programmed to press one of the available circles in a timed cycle, with 3 parameters:
\begin{itemize}
    \item $Clicking\ Interval\ (C_i)$: the amount of time between presses in seconds, so one of the circles is pressed every $C_i$ seconds;
    \item $Chance\ of\ Right\ Target\ (C_r)$: when pressing one of the circles, the \ac{AI} will choose what circle to press, the chance that it will choose the correct one is given by $C_r$;
    \item $Reaction\ Time\ (R_t)$: a circle is only be eligible to be pressed by the \ac{AI} $R_t$ seconds after it spawns, as to replicate the reaction time a human would have to recognize the circle.
\end{itemize} 
We wanted the agent to play rapidly, if a little recklessly, as to provide more opportunities for the participant to react and notice how he played, so we empirically found 0.5 seconds to be a good value for $C_i$, as it made the agent have a slightly above average human reaction time for pressing the circles. To $C_r$ we assigned 70\% success rate, as failing 30\% of the circles averaged out the agent's score to normal human achievable levels, and to $R_t$ we selected 0.3 seconds, as it is plausible value for a 30\% fail chance, as the agent simulates not entirely recognizing the number before pressing the circle.

\subsection{Trust Game}
\label{subsec:Trustgame}
Our overall scenario is very much based on the Trust/Investor Game, first proposed by Berg et al.~\cite{JoyceBergJohnDickhaut}, so we present a small introduction and discussion to the scenario. The game is set up with 2 anonymous players, which we will call player A and player B, where \$10 is given to player A and none to player B. In the first phase player A must choose how much of the starting \$10 should he give to player B knowing that the value will be tripled in player Bâ€™s hands. In the second phase player B chooses how much of the, now tripled, money will he return no player A.

This game forms a good base for our scenario because the decision of how much A should give to B is dependent on 2 different factors: the ability and willingness of B to multiply the investment and the willingness of B to return the profits of the investment. This is possible to perform because, while the source of the game explicit the multiplication factor of giving money to B, this value can be a hidden parameter, making the ability of B something to take into account.

We used this game as a foundation for our user studies, described further on in Section \ref{sec:UserStudies}, where we attempted to resolve some of it's faults, such as the game lack of any negotiation phase, in fact, both players are in separate rooms, with no way of interacting with one another, inducing trust to be modelled in a game theory point of view, which is contrary what we wish to accomplish.

\subsection{Results}
% Mostly inconclusive