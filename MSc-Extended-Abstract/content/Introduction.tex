% This is "Introduction.tex"
% A content sub-file for Trustfull Action Suggestion Thesis Extended Abstract
\section{Introduction}
\label{sec:Introduction}

% TODO - Insert motivation on the topic:
% - while a lot of reasearch has been done in modeling trust and in automation, little  research trust in HAI has been found
% - trust is an important component of the social fabric, and essential if we want to have collaboration
% - mention that people tend to "anthropomorphize" computers, applying social rules in computer interactions so trust becomes an interesting concern as shown in \cite{Reeves1998a} and \cite{Fogg1997}
% - First paragraph - Say that trust is a fundamental part of social interaction, and as agents try to simulate this,and by this reason there's been quite some focues in computational trust during recent years, (cite reviews). Give applications of the trust models (specially on e-commerce)
% - Second paragraph - Briefly say what has been done (not too much, leave for related work) and comment on what is lacking.
% - Third paragraph - Introduce your solution, and why it's going to improve the field. Relate to the comments mentioned previously
% - Fourth paragraph - Finally give the structure of the paper (and it's scope? check if hay is needed...)
Trust has been described in Psychology as being one of the most important components of interpersonal relationships \cite{Simpson2007}. It is undeniable the need of trust to promote cooperation and collaboration between two parties, specially regarding who should one trust and what is worth entrusting. So as \ac{AI} research gravitates towards the development of Intelligent Agent Systems \cite{Russell2009a}, a focal concern is the performance of collaborative tasks \cite{Grosz1996, Allen2007}. And while the amount of literature has been increasing, we found it surprising that not enough work has been done in \ac{HAI} focusing on trust, other than on design issues \cite{Bickmore2005} and the sub-field of \ac{HRI} \cite{Goodrich2007, VandenBrule2014}, specially when so much has been done regarding \ac{TiA} \cite{Jones1997, Lee2004}. This reveals that while the area has so much potential, the level of understanding is still very shallow, only deeply focused in certain areas \cite{Granatyr2015}.

\ac{MAS} Trust and Reputation modelling is one of the areas that has been having a great increase of interest lately, specially ever since the advent of \ac{P2P} e-commerce in platforms like \textit{eBay}\footnote{eBay Auctions: \url{http://www.ebay.com/}}. For this applications, tools and solutions to ensure trust were needed for a new reality of a mass amount of anonymous entities constantly entering and exiting the environment and performing trading transactions through an open space. However almost all research focuses purely on the creation and maintenance of a trust model about the environment around the agent, providing a rank for other agents, but not taking into account the agent's own stance in the environment. Additionally most of this models' designs are based in statistical and game theoretical concepts \cite{Granatyr2015} which makes them difficult to understand, analyse and, most importantly, describe their evaluative reasoning in a human understandable manner.
Castelfranchi and Falcone \cite{Castelfranchi1998} tried to solve these problems with the introduction of cognitive models, by mapping the trust model to the agent's mental state, composed by beliefs and goals, very akin to existing cognitive agent architectures like \ac{BDI} \cite{Rao1995}. Then some systems, like Repage \cite{Sabater2006}, created implementations of this new paradigm of trust modelling, where most of the models were purely theoretical.

Nevertheless, there is a gap in this area of research that we wish to address with our work: the lack of an implementation for an action suggester based on the agent's trust model, with the goal to improve the strength of our beliefs in the model and to improve trust in our agent. While one could argue that this is the responsibility of the decision making or planner component of the agent, we believe that a dedicated module will ease the complexity of decision by making it more modular, and also allowing for the trust model to take a more active part in the decision making process. To our knowledge, no attempts have been done towards this goal, so we propose to develop a Trust Model that: firstly, is capable of creating a cognitive model representing the mental state of the user's trust in the agent, following Castlefranchi and Falcone's concepts of Cognitive Trust Modelling and taking inspiration from Repage's architecture, and secondly, able to suggest what actions should be used to improve trust on the agent.

Developing this model also provided the opportunity to address Trust evaluation, as we found  a lack of scenarios in \ac{HAI} that would address Trust's two main components, Ability and Willingness, simultaneously. This urged us to design a scenario that would address this issues and remain relevant to other studies in this area. The scenario was developed in collaboration with Henriques' thesis work on \textit{Rapport - Establishing Harmonious Relationship Between Robots and Humans} \cite{Henriques2016}.




