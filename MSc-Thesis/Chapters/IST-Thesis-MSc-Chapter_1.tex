% #############################################################################
% This is Chapter 1
% !TEX root = ../main.tex
% #############################################################################
% Change the Name of the Chapter i the following line
\fancychapter{Introduction}
%\cleardoublepage
% The following line allows to ref this chapter
\label{chap:intro}

Trust has been described in Psychology as being one of the most important components of interpersonal relationships \cite{Simpson2007}. It is undeniable the need of trust to promote cooperation and collaboration between two parties, specially regarding who should one trust and what is worth entrusting.


As \ac{AI} research gravitates towards the development of Intelligent Agent Systems \cite{Russell2009a}, where a focal concern is the performance of collaborative tasks \cite{Grosz1996, Allen2002, Allen2007}, as well as addressing the problems of interaction between humans and agents \cite{Bradshaw2011}, one would consider that trust should be one of the main focuses of \ac{HAI}. Since the start of automated machinery, one of the main issues was how to properly manage trust on machines, in order to avoid over or under reliance \cite{Lee2004}. Reeves and Nass have shown that people apply social rules to \ac{HCI}, and this can logically be extended to the sub-field of \ac{HAI} \cite{Reeves1998a}. So as agents evolve to better perform collaborative tasks with humans autonomously, which demands at least some amount of social interaction, the active agent must seek out to improve the trust relationship it has with the user \cite{Lashkari1994}. And while the amount of literature has been increasing, we found it surprising that not enough work has been done in \ac{HAI} focusing on trust, other than on design issues \cite{Bickmore2005} and the sub-field of \ac{HRI} \cite{Goodrich2007, VandenBrule2014}, specially when so much has been done regarding \ac{TiA} \cite{Lee1992, Jones1997, Lee2004}. This reveals that while the area has so much potential, the level of understanding is still very shallow, only deeply focused in certain areas \cite{Granatyr2015}.

\ac{MAS} Trust and Reputation modelling is one of the areas that has been having a great increase of interest lately, specially ever since the advent of \ac{P2P} e-commerce in platforms like \textit{eBay}\footnote{eBay Auctions: \url{http://www.ebay.com/}}. For this applications, tools and solutions to ensure trust were needed for a new reality of a mass amount of anonymous entities constantly entering and exiting the environment and performing trading transactions through an open space. However almost all research focuses purely on the creation and maintenance of a trust model about the environment around the agent, providing a rank for other agents, but not taking into account the agent's own stance in the environment. Additionally most of this models' designs are based in statistical and game theoretical concepts \cite{Granatyr2015} which makes them difficult to understand, analyse and, most importantly, describe their evaluative reasoning in a human understandable manner.
Castelfranchi and Falcone \cite{Castelfranchi1998} tried to solve these problems with the introduction of cognitive models, by mapping the trust model to the agent's mental state, composed by beliefs and goals, very akin to existing cognitive agent architectures like \ac{BDI} \cite{Rao1995}. Then some systems, like Repage \cite{Sabater2006}, created implementations of this new paradigm of trust modelling, where most of the models were purely theoretical. Cognitive Trust modelling also opened the doors for a more complete definition of Trust, by adding more dimensions to trust, such as how the task being delegated affecting the trustor's evaluation of the trustee, but the relevant beliefs about the trustor's ability and willingness being able to be completely independent on the task, and even transferable from similar but different experiences with the trustor (e.g. Although I never experienced Jim's cookie baking, I can assert them to be fairly good from my experience with his cakes).

Nevertheless, there is a gap in this area of research that we wish to address with our work: the lack of an implementation for an action suggester based on the agent's trust model, with the goal to improve the strength of our beliefs in the model and to improve trust in our agent. While one could argue that this is the responsibility of the decision making or planner component of the agent, we believe that a dedicated module will ease the complexity of decision by making it more modular, and also allowing for the trust model to take a more active part in the decision making process. To our knowledge, no attempts have been done towards this goal, so we propose to develop a Trust Model that: firstly, is capable of creating a cognitive model representing the mental state of the user's trust in the agent, following Castlefranchi and Falcone's concepts of Cognitive Trust Modelling and taking inspiration from Repage's architecture, and secondly, able to suggest what actions should be used to improve trust on the agent.

Developing this model also provided the opportunity to address Trust evaluation, as we found  a lack of scenarios in \ac{HAI} that would address Trust's two main components, Ability and Willingness, simultaneously. This urged us to design a scenario that would address this issues and remain relevant to other studies in this area. The scenario was developed in collaboration with Henriques' thesis work on \textit{Rapport - Establishing Harmonious Relationship Between Robots and Humans} \cite{Henriques2016}.


\section{Thesis Challenge}
This thesis aims to tackle the development of a Cognitive Trust Model capable of representing an agent's trust beliefs and suggest trust improving actions, depending on the trust model's current state.


\section{Contributions}
The contributions this thesis provides are the Cognitive Trust Model, and the Quick Numbers scenario for Trust and Rapport evaluation.
\begin{center}
    $\ast$
\end{center}
In the remainder of the document we will present a brief summary of the main concepts used throughout the thesis in Chapter \ref{chap:Background}. Then in Chapter \ref{chap:RelatedWork}, we will discuss some of the work done in modelling trust for \acp{MAS} and measuring trust in \ac{HRI} applications. Following that, we will discuss our developed Trust Model in Chapter \ref{chap:TrustModel}. Chapter \ref{chap:Scenario} reveals our Quick Numbers scenario design, and in Chapter \ref{chap:UserStudies} we show it's application in a user study to evaluate the model. Finally in Chapter \ref{chap:Conclusions} we will draw some conclusions of the work done and provide some future work ideas.