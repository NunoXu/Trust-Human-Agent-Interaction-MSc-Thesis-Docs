\section{Conclusion}
\label{sec:Conclusion}
We started by introducing our thoughts about the lack of research done in the area of trust in \ac{HRI}, especially regarding trust improvement, and how we want to address that issue by tackling one of the gaps exposed in the research: action suggestion to improve trust and their beliefs. So we summed up our main goal as to develop an action suggestion module capable of giving out actions that will improve trust in the agent. Then we went on to establish some background concepts specific to the domain, like the definitions of trust and what we think it is more appropriate for our work, as there is no literary consensus on which one is the best. 

We delved into some of the \ac{MAS} trust models we found. While there were many more aside from those discussed in this report, we wanted focus on the ones that followed the trust paradigm that most closely related with what we intend to accomplish with this project. So we presented the most interesting cognitive trust models, particularly Repage and \textit{BC}-logic, followed by a work regarding trust evaluation in \ac{HRI}, which we will use for project evaluation.

As we have not found any previous attempt to creating a trustful action suggestion system, we still do not have any particular solution to the problem, so this will be the focal point of research and development for the remainder of this thesis. Nevertheless the module must be supported by a trust model, which we will implement basing our design and architecture on Repage and \textit{BC}-logic.