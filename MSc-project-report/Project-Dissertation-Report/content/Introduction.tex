\section{Introduction}
\label{sec:Introduction}

% TODO - Insert motivation on the topic:
% - while a lot of reasearch has been done in modeling trust and in automation, little  research trust in HAI has been found
% - trust is an important component of the social fabric, and essential if we want to have collaboration
% - mention that people tend to "anthropomorphize" computers, applying social rules in computer interactions so trust becomes an interesting concern as shown in \cite{Reeves1998a} and \cite{Fogg1997}
% - First paragraph - Say that trust is a fundamental part of social interaction, and as agents try to simulate this,and by this reason there's been quite some focues in computational trust during recent years, (cite reviews). Give applications of the trust models (specially on e-commerce)
% - Second paragraph - Briefly say what has been done (not too much, leave for related work) and comment on what is lacking.
% - Third paragraph - Introduce your solution, and why it's going to improve the field. Relate to the comments mentioned previously
% - Fourth paragraph - Finally give the structure of the paper (and it's scope? check if hay is needed...)
Trust has been described in Psychology as being one of the most important components of interpersonal relationships \cite{Simpson2007}. It is undeniable the need of Trust to promote cooperation and collaboration between two parties, either in deciding who should one collaborate with, or even on what we should the other party with. Since the start of automated machinery, one of the main issues was how to properly manage trust on machines, in order to avoid over or under reliance\cite{Lee2004}.

As \ac{AI} Research gravitates towards the development of Intelligent Agent Systems \cite{Russell2009a}, out of which a focal concern is the performance of collaborative tasks\cite{Grosz1996, Allen2002, Allen2007}, as well as addressing the problems of interaction between humans and agents\cite{Bradshaw2011}, one would consider that Trust should be one of the main focus on \ac{HAI}. While the amount of literature has been increasing, we found surprising that not enough work has been done in \ac{HAI} focusing on Trust, other than on design issues\cite{Bickmore2005} and the sub-field of \ac{HRI}\cite{Goodrich2007, VandenBrule2014}, specially when so much has been done regarding Trust in Automation \cite{Lee1992, Jones1997, Lee2004}  and in modelling Trust and Reputation in \ac{MAS}\cite{Granatyr2015}.

Reeves and Nass have shown that people apply social rules to \ac{HCI}, and this can logically be extended to \ac{HAI}\cite{Reeves1998a}. So as autonomous agents evolve to better perform collaborative tasks with humans, which demands some amount of social interaction, the active agent must seek out to improve the trust relationship it has with the user \cite{Lashkari1994}. To that goal, we propose to develop two self-contained agent modules, firstly, capable of creating a cognitive model representing the mental state of the user's trust in the agent, and secondly, provide input on what actions should be used to improve or worsen trust on the agent. We will ascertain this project's correctness by integrating the module in an agent implementation, currently in development, that runs the scenario \textit{Split or Steal}, introduced in the British game show \textit{Golden Balls}\cite{Wikipedia.Golden.Balls}.

This will allow, not only to ensure proper reliance in the agent's task \cite{Lee2004}, but to also provide additional insight on how certain actions affect human trust on agents differently from one another. It can also be used to improve the trust component of long-term relationships between Agents and Humans \cite{Bickmore2001b}.


\subsection{Goals}
\label{subsec:Goals}
% Clearly state what must be done to consider this thesis a success (may prove difficult as it's too abstract) maybe focus on objective marks on trust improvement of the subject.
% Need to go fetch what is the trust measurement questionaires.

% we aim to create a generic agent model that combines the already extensive reasearch in trust modeling in MAS systems with a decision making module with strategies to improve trust in the agent.
% we want to focus on human to agent interaction. so improve and model human trust.
% find out which parameters and features can be explicitly chosen to human modeling.
In sum, this project's purpose will be to:
\begin{itemize}
	\item Create a cognitive trust model capable of representing human trust towards the agent;
	\item Develop a decision making module that aims to rank actions as positively or negatively affecting trust in the agent;
	\item Study what factors influence trust in certain interactive actions.
\end{itemize}


In Section \ref{sec:Background} we will present a brief summary of main concepts used in this project. Section \ref{sec:Related Work} will discuss the trust models already developed in the field of \ac{MAS}. Then in Section \ref{sec:Solution} a description of our solution architecture will be presented. Finally in Section \ref{sec:Evaluation} we will describe how we will evaluate the objectives.


