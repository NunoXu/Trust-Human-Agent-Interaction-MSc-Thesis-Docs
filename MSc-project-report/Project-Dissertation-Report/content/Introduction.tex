\section{Introduction}
\label{sec:Introduction}

% TODO - Insert motivation on the topic:
% - while a lot of reasearch has been done in modeling trust and in automation, little  research trust in HAI has been found
% - trust is an important component of the social fabric, and essential if we want to have collaboration
% - mention that people tend to "anthropomorphize" computers, applying social rules in computer interactions so trust becomes an interesting concern as shown in \cite{Reeves1998a} and \cite{Fogg1997}
% - First paragraph - Say that trust is a fundamental part of social interaction, and as agents try to simulate this,and by this reason there's been quite some focues in computational trust during recent years, (cite reviews). Give applications of the trust models (specially on e-commerce)
% - Second paragraph - Briefly say what has been done (not too much, leave for related work) and comment on what is lacking.
% - Third paragraph - Introduce your solution, and why it's going to improve the field. Relate to the comments mentioned previously
% - Fourth paragraph - Finally give the structure of the paper (and it's scope? check if hay is needed...)
One of the main focus on \ac{AI} Research in recent years has been in the development of Intelligent Agent Systems \cite{Russell2009a}, out of which a concern is the performance of collaborative tasks\cite{Grosz1996, Allen2002, Allen2007}. Also to that end, an emergent concern has been to address the problems of interaction between humans and agents\cite{Bradshaw2011}. And while the amount of literature has been increasing, especially in \ac{HRI}\cite{Goodrich2007}, not much work has been done in \ac{HAI} focusing on Trust, specially when so much has been done in modelling Trust and Reputation in \ac{MAS}\cite{Granatyr2015} and Trust in Automation \cite{Lee1992, Jones1997, Lee2004}.

Reeves and Nass have shown that people apply social rules to \ac{HCI}, and this can logically be extended to \ac{HAI}\cite{Reeves1998a}. So as autonomous agents evolve to better perform collaborative tasks autonomously with humans, which demands some amount of social interaction, the active agent must seek out to improve the trust relationship it has with the user \cite{Lashkari1994}. And to that goal we propose to develop a self-contained agent module capable of analysing and modelling the current   Not only to ensure a proper reliance in the agents task \cite{Lee2004}, but to also 


This thesis will try to model trust as multidimensional, where trust can be measured through a great variety of factors, including bias towards machines and intelligent systems. So this work will use a game environment, where players will have to cooperate in order to reach the game objectives, additionally the players will have to trust each other and that they will act according to plans. This allows for different arrangements of human and agent players to be tried and analysed.




\subsection{Objectives}
\label{subsec:Objectives}
% Clearly state what must be done to consider this thesis a success (may prove difficult as it's too abstract) maybe focus on objective marks on trust improvement of the subject.
% Need to go fetch what is the trust measurement questionaires.

% we aim to create a generic agent model that combines the already extensive reasearch in trust modeling in MAS systems with a decision making module with strategies to improve trust in the agent.
% we want to focus on human to agent interaction. so improve and model human trust.
% find out which parameters and features can be explicitly chosen to human modeling.
This project's purpose will be to:
\begin{itemize}
	\item Create a trust model capable of representing human trust towards the agent;
	\item Develop a decision making module that aims to suggest actions that maximize trust towards the agent;
	\item 
\end{itemize}



