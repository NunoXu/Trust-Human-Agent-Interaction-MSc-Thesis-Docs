\section*{Appendices}
\section{Variants of Single-subject designs}
\label{app:SSD}

\newpage
\begin{landscape}
	\section{Educational software}
	\label{app:Educational}	
	landscape page
\end{landscape}













%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Dirk Haylen et al., developed an iterative model of developing a data-driven model for generating timings for backchannels behaviors in a dyadic conversational setting. On the one hand, it is data-driven because it uses \ac{ML} algorithms. On the other hand, it is iterative because the learning phase is done through several iterations, each one is more refined than the previous one contributing to the overall growth of the rapport agent's quality.

It will be first described the system developed by the authors and the issues they focused on. Following, it will be described how the system was evaluated with sufficient detail. To conclude, it will be discussed the innovation introduced in this system comparing with previous models followed by referring the important positive and negative aspects as well how the work developed by Dirk Haylen et al. is relevant to the proposed solution section \ref{sec:Solution}.

\subsubsection*{System description}
In data-driven timing generation for social behaviors, using \ac{ML} techniques, it is retrieved two types of samples: positive samples representing the moments (or timings) in the interaction that are socially acceptable to generate a backchannel gesture (e.g., a head nod or a vocalization "hmm hmm") and negative samples as the moments when it is unacceptable. As described in section XX, in previous approaches, corpus based, positive samples are taken directly from the annotated dataset and the negative randomly as long as they do not overlap with a positive sample. 

Taken this into account, the author mentions that this approach potentially leads to a great number of false negative by not taking into account that social signals are optional and a reflection of the listener's personality and therefore behavior different from the corpus can also be socially appropriate. As such, in order to tackle this problem they identified which moments in the interaction are seen as socially inappropriate using subjective rating in each iteration and used this information to improve the quality of the model.

In the proposed iterative approach, both positive and negative samples are collected to further refine the classifier using a sequence of a bootstrap and iterations of three procedures: generation, evaluation and learning.

During the generation (pink areas on Figure \ref{fig:ipl_system}), three steps occur:
\begin{enumerate}
	\item \textbf{Extraction of features}: Using the available sensors (for example camera and microphone), it is created a feature vector with the representation of dialog's partner's behavior at a given instance;
	\item \textbf{Classification of features}: Each feature vector is assigned a score, using the model trained in previous iterations, representing the probability of generating a backchannel in a given instance is socially appropriate;
	\item \textbf{Stimulation generation}: the scores are transformed to a sequence of social behavior timings and with application of heuristics (e.g., top N scores, minimum score value or maximum number of timings per minute) the listener's social behavior animation is computer generated and synchronized with the speaker's video to be evaluated in the evaluation procedure.
\end{enumerate}

\begin{figure}[htbp]
	\centering
	%\includegraphics[width=0.5\textwidth]{./images/IPL_system.png}
	\caption{Taken from \cite{Kok2012}. Schematic representation of the Iterative Perceptual Learning framework. The generation, evaluation and learning stage are shown in pink, blue and green, respectively.}
	\label{fig:ipl_system}
\end{figure}

During the evaluation (blue areas on Figure \ref{fig:ipl_system}), using \ac{PCS} (PÔR NO BACKGROUND), multiple subjects rate the quality of the timings generated by the model by pressing a button whenever they would rate the agent's behavior as socially inappropriate (the \textit{yuck} button, introduced by Poppe et al. [15]). Filters such as minimum number of \textit{yuck}s per social behavior or mis-presses can be applied. Additionally, it is taken into account the typical delay when pressing the button.

During the final procedure, learning (green areas on Figure \ref{fig:ipl_system}), the retrieved positive and negatives samples are used to train the classifier. Each iteration contributes with more samples to model and therefore increasing the quality of the identified timings for generation of the agent's social behaviors. As the author describes, this can be seen as a form of reinforcement learning by focusing on the relevant moments.

During the bootstrap (yellow area on Figure \ref{fig:ipl_system}): Since, it is not possible to have non-random negative samples before using subjective evaluation the classifier will be trained using the corpus based approach: the positive samples are taken directly from the corpus and the negative samples are taken at random instance that do not overlap with the first samples. After generating and evaluating the generated timings (using the \textit{yuck} button), these negative samples are discarded and replaced by the ones obtained form the subjective evaluation.

This approach allows the model to be refined in each iteration and focus on the negative samples subjectively evaluated by multiple users using the \ac{PCL} approach. Moreover, the model is refined in each iteration and has more understanding about proper timings for social behaviors.

\subsubsection*{Experiment}
The developed \ac{IPM} model was compared with the traditional corpus-based on a face-to-face conversation with a virtual agent as listener and a human subject as speaker. It was used \ac{SVM} as classifier with the default values: RBF kernel with $c = 1$ and $\gamma = 1/x$, where $[|x|$ is the dimensionality of the input vector. The corpus used to train and evaluate the model is the Dutch-spoken \textit{MultiLis} corpus [21] with 131 minutes of dyadic conversations between two subjects in cubicles interacting with one another using video conferencing with the camera positioned behind an interrogation mirror with the other user projected to recreate the looking into the eye. From the audio and the video of the \textit{MultiLis} corpus it was extracted three types of features: prosody (112 features), speaking (1 feature) and looking (1 feature based on manual annotations). The pre-processing details are dependent on the used corpus and are detailed in the paper [X].

During the creation of the baseline (bootstrap), the training was done using a frequency of 100 Hz. The positive samples were the first frame in the annotated corpus. However to make the classifier less dependent on such single frame it was selected 4 frames around it such that they were sampled using a normalized Gaussian distribution with a $\epsilon$ with 95\% of the samples within 250ms of the positive sample. Finally, it was selected an equal number of negative samples and smoothed the output of the \ac{SVM} to create curves that represent the appropriateness to provide a backchannel. The local peaks were used to identify the moments in the interactions adequate to produce a backchannel.

During the generation procedure it was generated 25\% more backchannels than the determined mean backchannel rate over all interactions in the MultiLis corpus to collect more negative samples to be used in subsequent iterations. During the evaluation process, participants had to press the \textit{yuck} button whenever they perceived an individual backchannel from the virtual listener as inappropriate. The presses were matched to the last preceding backchannels if within 5000 ms of the onset. Finally, it was measured the number of \textit{yucks} for each synthesized backchannel. In the last step, learning, the negative samples that were taken randomly are discarded and substituted by those collected during the subjective evaluation. The number of positive and negative samples was balanced using Gaussian models, sampling factor and number of negative samples. The only restriction applied was that two backchannels could not be within 2 seconds from each other.

For the experiment it was used one bootstrap phase and 4 iterations using the three procedures mentioned. The stimuli was a speaker’s video from the corpus with a animated listener synchronized. The virtual agent only nodded his head while making an utterance whenever appropriate. As the author refers that head movement, posture shifts, facial expressions and eye blinks were not animated to not impact the focus of the subject. For each iteration, all positive and negative samples obtained from all previous iterations were used to learn the IPL model. Only the negative samples from the bootstrap iteration were discarded since they were evaluated subjectively by the users as inappropriate.

\subsubsection*{Evaluation}
Both models, corpus based and \ac{IPL} were trained using the same interactions to make a fair comparison. It is important to note that the evaluation results for the IPL double as negative samples for model learning in the subsequent iteration.

Participants of a 30 minutes experiment were shown stimuli through a webpage and that they were explained that they would had to evaluate the quality of the synthesized listening behavior. The subjects has to press the spacebar each time the virtual listener perfomed a backchannel they judged as inapproriate and they replay and change or discard their choices. It was shown both the IPL model and the corpus based model allowing the comparison between them pair-wise.

%%% Participants %%%%

To measure the results, it was used two measurements:
\begin{itemize}
	\item Objective measure: Compare the predicted timing of the backchannel with those performed by the actual listener in the MultiLis corpus. The precision and recall was combined using weighted harmonic mean into $F_{1} = \frac{2pr}{p+r}$;
	\item Subjective measure: Use the \textit{yucks} collected during the perceptual evaluation. It was calculated the percentage of backchannels that did not receive any yucks and the average of \textit{yucks} per backchannel;
\end{itemize}

After iteration the corpus based model was compared with the \ac{IPL} model.  

\subsubsection*{Discussion}