% More than a literature review
% Organize related work - impose structure
% Be clear as to how previous work being described relates to your own.
% The reader should not be left wondering why you've described something!!
% Critique the existing work - Where is it strong where is it weak? What are the unreasonable/undesirable assumptions?
% Identify opportunities for more research (i.e., your thesis) Are there unaddressed, or more important related topics?
% After reading this chapter, one should understand the motivation for and importance of your thesis
% You should clearly and precisely define all of the key concepts dealt with in the rest of the thesis, and teach the reader what s/he needs to know to understand the rest of the thesis.


\section{Related Work}
\label{sec:Related Work}
Computational Trust research has been focused on modelling trust in \acp{MAS}, specially on open e-commerce environments\cite{Granatyr2015, HanYu2013, Pinyol2013, Noorian2010, Huang2008}, with at least 106 models created\cite{Granatyr2015}, since the formalization of trust as a measurable property by Marsh in 1994 \cite{Marsh1994}. We will present some trust models from which we will take inspiration while creating our own, and some work done in measuring trust in \ac{HRI}.

\subsection{Trust Models}
\label{subsec:Related work:Trust Models}
For related work concerning Trust Models we will focus on \textbf{Cognitive} Trust Models, first introduced by Castelfranchi and Falcone\cite{Castelfranchi1998}, as we want to focus on modelling trust through multiple dimensions, with the intent of having trust depend on the action to perform, context and agent performing the task and having these dimensions represented explicitly in the model, something that it is not possible with \textbf{Numerical}, like the one introduced by \cite{Marsh1994}.

\subsubsection{Castelfranchi and Falcone}
Having developed the concept of Cognitive Trust Models, this author's model is generally regarded as a classical basis for most other authors, and while we will not use the entirety of this model, it is worth describing, as it was also a source of inspiration to other authors referenced in this report. 
The model is characterised around their definition referred in Section \ref{subsubsec:CastelfranchiTrust}, through a central core, composed by a five-part relation, between:
\begin{itemize}
	\item the trustor (\textbf{X});
	\item the trustee (\textbf{Y});
	\item the context where they are inserted in (\textbf{C});
	\item a task ($\bm{\tau}$) defined by the pair $(\alpha, \rho)$, where \bm{$\alpha$} is the action  entrusted to the trustee, that possibly produces an outcome \bm{$\rho$}, contained in the goal of X ($g_x$);
	\item the goal of the trustor (\bm{$g_x$}).
\end{itemize}
More shortly represented by equation \ref{eq:TrustRelation}.
\begin{equation}
TRUST(X\ Y\ C\ \tau\ g_x)
\label{eq:TrustRelation}
\end{equation}
This defines Trust as goal-oriented, contextual, and multi-dimensional, as from the point of view of the trustor, it varies not only on the trustee, but also from the overall context, the action that is being delegated, and the particular goal of the trustor. For example, if the goal of the trustor is simple to perform and not very critical to him, he may be more willing to delegate the task, and trust another agent to perform such task. Adjustments can be attached to this core adjusting better to the context in which it may be used. For instance, one may add an authoritative third party element to the relation in supervised security applications.

The model also conceptualizes \textbf{Expectation} as a belief of when agent X awaits for $\rho$ to happen when an action $\alpha$ trusted to Y is being performed, formalized in first order logic in equation \ref{eq:TrustExpectation}.
\begin{equation}
	\begin{aligned}
		(\text{\textit{Expectation}}\ X\ \rho) \implies (Bel_x^{t'} &(\text{\textit{will-be-true}} ^ {t''} \rho)) \wedge (Goal_x^{Period(t', t''')} \\
														&(KnowWhether_X (\rho\ OR\ \text{\textit{Not} } \rho)^{t''}))
	\end{aligned}
	\label{eq:TrustExpectation}
\end{equation}
This can be used to establish what expectations the user should have in the agent, whether initial or constructed during interaction, and provide an additional measure to weight the importance of certain agent functions and actions.

As stated in the definition (Section \ref{subsubsec:CastelfranchiTrust}) the mental attitude of the trustor is defined by beliefs of the qualities and faults of Y, so when can quantify the strength of our belief in this attribute by defining it's \textbf{Degree of Credibility} (DoC), which is defined by a function that takes in the trustor \textbf{X}, trustee \textbf{Y} and task \bm{$\tau$}, as shown in equation \ref 

\begin{equation}
	\begin {aligned}
	DoC_X&(Qual-i_{(s1, ...sn), Y} (\tau)) = F_{X, Y, \tau} (Bel_X(Str_1 Qual-i_{s1Y}(\tau)), \\
		 &Bel_X(Str_2 Qual-i_{s2Y}(\tau)), ..., Bel_X(Str_n Qual-i_{snY}(\tau))) \\
	\end {aligned}
	\label{eq:DegreeOfCredibility}
\end{equation}

\textbf{Degrees of Trust} quantify the Trust level agent X has in Y with action $\alpha$ according to the formula depicted in \ref{eq:DegreeOfTrust}.
\begin{equation}
	\begin{aligned}
		DoT_{XY\tau} =\ &c_{Opp}\ DoC_x[Opp_y(\alpha, \rho)] \times\\
					    \times\ &c_{Ability_y}\ DoC_x[Ability_y(\alpha)]\times \\
					    \times\ &c_{WillDo}\ DoC_x[WillDo_y(\alpha, \rho)]
	\end{aligned}
	\label{eq:DegreeOfTrust}
\end{equation}
Where 


\subsubsection{Repage}


\subsubsection{BDI + Repage}

\subsection{The Perception and Measurement of Human-Robot Trust}
\label{subsec:Related work:The Perception and Measurement of Human-Robot Trust}

Schaefer\cite{Schaefer2009} presents a trust perception scale, that provides a way of extracting an accurate trust score from humans interacting with robots. The scale is composed of 40 items that can be ranked from 0 to 100, in 10 point intervals. The final result it then averaged by adding all the item values and divided by the total number of items (40).



While this work has been done specifically for \ac{HRI} we believe that a sub-set of this items can be used for the features used in the cognitive model of the user's trust, further described in Section %todo give refence here





% O que fizeram?
% Como se enquadra?
% Porque é importante?
% Como pode ser útil?

\subsection{Discussion}
\label{subsec:RelWorkDiscussion}

Based on everything and what everyone is doing or done, these are the problems, these are the advantageous and disavantageous of the aproach.