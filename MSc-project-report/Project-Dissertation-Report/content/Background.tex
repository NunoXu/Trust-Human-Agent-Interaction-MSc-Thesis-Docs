\section{Background}
\label{sec:Background}

% Reference 3 types of agents that may be applicable to the project: 
% - Social Agents
% - Afective Agents
% - Anthromorphic Agents
% --- Embodied Conversational Agents (ECAs)

% When talking about trust and reputation mention the differences between both.
% Tell what is a trust model and what is a reputation model

Before discussing related work and our solution to the problem, we will present the main concepts concerning Trust.

\subsection{Trust}
\label{subsec:Trust}
Trust is regarded throughout the literature as one of the fundamental components of human society, being essential in cooperative and collaborative behaviour. So it has been studied in a multitude of disciplines, from Psychology and Sociology, to Philosophy and Economy\cite{Sabater2005}. For that reason, it is no wonder that it acquired a very large number of different definitions through the years of study, causing the problem of not existing a consensus on a definition of trust\cite{Castelfranchi2010}. In the field relevant to us, Computational Trust, three main definitions exist:
\begin{itemize}
	\item 'Trust is the \textit{subjective probability} by which an individual A, \textit{expects} that another individual, B, performs a given action on which its \textit{welfare depends}' (taken from \cite{Castelfranchi2010}), by Gambetta \cite{Gambetta2015}. This is accepted by most authors as one of the most classical definitions of trust.
	
	\item Marsh was the first author to formalize trust as a Computational Concept\cite{Marsh1994}, continuing the perspective of reducing trust to a numerical value, but also adding that: X trust Y if and only if 'X \textit{expects} that Y will behave according to X's best interest, and will not attempt to harm X' (taken from \cite{Castelfranchi2010}).
	
	\item Castelfranchi and Falcone then defined 
\end{itemize}