\section{Background}
\label{sec:Background}

% Reference 3 types of agents that may be applicable to the project: 
% - Social Agents
% - Afective Agents
% - Anthromorphic Agents
% --- Embodied Conversational Agents (ECAs)

% When talking about trust and reputation mention the differences between both.
% Tell what is a trust model and what is a reputation model

Before discussing related work and our solution to the problem, we will present the main concepts that  will be mentioned in the rest of this report, specifically regarding Trust, Reputation and Game Theory.

\subsection{Trust}
\label{subsec:Trust}
Trust is regarded throughout the literature as one of the fundamental components of human society, being essential in cooperative and collaborative behaviour. So it has been studied in a multitude of disciplines, from Psychology and Sociology, to Philosophy and Economy\cite{Rousseau1998, Jones1997, Sabater2005}. For that reason, it is no wonder that it acquired a very large number of different definitions throughout the years of study, causing the problem of not existing a consensus on a definition of trust\cite{Castelfranchi2010}. But in the scope of this project, the most relevant start for our discussion is the dyadic definition of trust, where it is defined as: 'an orientation of an actor (the truster) toward a specific person (the trustee) with whom the actor is in some way interdependent' (taken from \cite{Simpson2007}), as we want to focus on interpersonal relationships. This definition has been expanded throughout the literature, often adapted to fit the context or scope of the work, but three main definitions are highlighted:
\begin{itemize}
	\tallitem First, Gambetta\cite{Gambetta1988} defined trust as follows: 'Trust is the \textit{subjective probability} by which an individual A, \textit{expects} that another individual, B, performs a given action on which its \textit{welfare depends}' (taken from \cite{Castelfranchi2010}). This is accepted by most authors as one of the most classical definitions of trust, but we agree with \cite{Castelfranchi2010}, in that it is restrictive it's uni-dimensionality, as it only refers to predictability of the trustor, and does not take into account competence in executing the given action.
	
	\tallitem Marsh\cite{Marsh1994} was the first author to formalize trust as a measurable Computational Concept, continuing the perspective of reducing trust to a numerical value, set by Gambetta\cite{Gambetta1988}, but also adding that: X trusts Y if, and only if, 'X \textit{expects} that Y will behave according to X's best interest, and will not attempt to harm X' (taken from \cite{Castelfranchi2010}). In this definition our opinions also match with \cite{Castelfranchi2010}, regarding that it does not represent other parts of trust, such as the notion that trustor must ascertain some risk from delegating the action to the trustee.
	
	\tallitem Castelfranchi and Falcone then defined a new definition and paradigm for Computational Trust, introducing a Cognitive aspect to it\cite{Castelfranchi1998}. They define Trust as the mental state of the trustor and the action in which the trustor refers upon the trustee to perform. This is the definition of trust that we will adopt throughout the rest of the report, as it represents a vision of trust that takes into account the trustor set of beliefs and intentions, approaching it to an agent's cognitive model, while also linking trust to the action being performed, as one might trust another for certain types of actions and not for others (e.g. I may trust my squire to polish my sword, but not to swing it.).
\end{itemize}

\subsubsection{Castelfranchi and Falcone's Trust}
\label{subsubsec:CastelfranchiTrust}
More explicitly, Castelfranchi and Falcone\cite{Castelfranchi1998} state that Trust can be defined with a central core, composed by a five-part relation, between the trustor, the trustee, the context where they are inserted in, the action and outcome done by the trustee, and the goal of the trustor. This defines Trust as goal-oriented, contextual, and multi-dimensional, as from the point of view of the trustor, it varies not only on the trustee, but also from the overall context, the action that is being delegated, and the particular goal of the trustor. For example, if the goal of the trustor is simple to perform and not very critical to him, he may be more willing to delegate the task, and trust another agent to perform such task. Adjustments can be attached to this core adjusting better to the context in which it may be used. For instance, one may add an authoritative third party element to the relation in supervised security applications. It's important to note, that following this definition, Trust must imply that the trustor is taking some kind of risk by delegating a task to the trustee. Be it is because the trustee may not able to perform the task, or that he may purposely ruin the task and go against the trustor goals.

From this definition we should also address one important component, \textbf{Delegation}, which consists in: `the delegating agent (X) needs or likes an action of the delegated agent (Y) and includes it in her own plan: X relies, counts on Y. X plans to achieve gX through Y. So, she is formulating in her mind not a single-agent but a multi-agent plan and Y has an allocated share in this plan: Yâ€™s delegated task is either a state-goal or an action-goal' as stated in \cite{Castelfranchi1998}.



\subsection{Reputation}
\label{subsec:Reputation}
Reputation is also a concept that appears very often linked with Trust in the literature, specially since recent models created for representing trust have been focused on \acp{MAS} (see \cite{Abdul-rahman2000, Sabater2002, Sabater2006, Huynh2006, Pinyol2009}), where more recent Trust models have been developed to also include reputation as a source of Trust, where the agent is not influenced only by the image one has of the subject, but also by what other agents say about it.

For the purpose of this report, reputation of an agent is defined as the combined trust opinion that the other agents that have manifested or provided about a particular subject. This reputation can and should be different from the individual image that various agents may have about the subject.


\subsection{Game Theory}
\label{subsec:GameTheory}
Game Theory is the field of study that defines and analyses situations involving conflict or cooperation between multiple intelligent decision makers. These situations are called a game, and they are distilled to their core argument, by defining the limited and simple set of actions that the players may perform, and how do they affect the players. It then analyses the decision strategies for each player, by assuming that both will try to maximise their payoff (how much the player gains) with their action. To better explain the concepts we want to present, we will introduce one of the most common exemplary models of Game Theory, the Prisoner's Dilemma.

\subsubsection{Prisoner's Dilemma}
\label{subsubsec:PrisonersDilemma}
The Prisoner's Dilemma is a two player game and is usually described as follows:

Two criminal partners are arrested and locked in separate cells with no way of communicating with each other. They are then questioned separately, where they are given 2 options, betray the other prisoner by testifying against him, or remain silent, with the following outcomes:
\begin{itemize}
	\item If both prisoners betray each other, both get 2 years in prison;
	\item If one of them betrays and the other remains silent, the betrayer goes free and the other gets 3 years in prison;
	\item If both remain silent, both get just 1 year in prison;
\end{itemize}

We can represent betraying as \textit{Defecting} (D), and staying silent as \textit{Cooperating} (C), and name the players \textit{player1} and \textit{player2}. So the game's possible outcomes can be represented by a payoff matrix, like the one in Table \ref{PrisonerDilemaPayoffMatrix} where each entry represents a tuple of the form (\textit{player1} payoff, \textit{player2} payoff). As the goal is to not get years in prison, the payoffs correspond to $Max\ years\ in\ prison - years\ got\ in\ prison$.

\begin{table}[]
	\centering
	\begin{tabular}{l|l|l|}
		\cline{2-3}
		& $C_2$   & $D_2$   \\ \hline
		\multicolumn{1}{|l|}{$C_1$} & 2,2 & 0,3 \\ \hline
		\multicolumn{1}{|l|}{$D_1$} & 3,0 & 1,1 \\ \hline
	\end{tabular}
	\caption{Prisoner's Dilemma Payoff Matrix}
	\label{PrisonerDilemaPayoffMatrix}
\end{table}	

In the game we can say that \textit{Defecting} \textbf{dominates} \textit{Cooperating}, as for any action that the adversary player may choose, \textit{Defecting} always gives a better payoff for the individual player\cite{Nash1951}.

